library(rtweet)
library(tm)
library(wordcloud)
library(syuzhet)
library(dplyr)
tweets <- search_tweets("@UP80BR", n=500, lang="pt")
typeof(tweets)
#convertendo para formato DF
#tweets <- twListToDF(tweets)
dataFrame <- tweets %>%
as_tibble()
tweets <- dataFrame$text
#pontuando os tweets
s<-get_nrc_sentiment(tweets)
#plotando grafico com sentimentos
barplot(colSums(s), las=2, col=rainbow(10),
ylab = "Contagem", main = "Sentimentos com a palavra @UP80BR em 500 tweets")
VS <- VectorSource(tweets)
corpus <- Corpus(VS)
#Verificar o corpus gerado
inspect(corpus)
#limpeza
#tudo minúsculo
corpus <- tm_map(corpus, content_transformer(tolower))
#removendo pontuação
corpus <- tm_map(corpus, removePunctuation)
#removendo espaços extras em branco
corpus <- tm_map(corpus, stripWhitespace)
#remover numeros
corpus <- tm_map(corpus, removeNumbers)
#remover stopwords
corpus <- tm_map(corpus, removeWords, stopwords('portuguese'))
#verificação
inspect(corpus)
#converter para o formato de matrix
tdm <- as.matrix(TermDocumentMatrix(corpus))
#Fornecer as frequencias ordenadas de cada palavra
fre <- sort(rowSums(tdm), decreasing = TRUE)
#escolhedo um subconjunto dos dados
aux<- subset(fre, fre>2)
#plotar gráfico de barras
barplot(aux, las=2, col = rainbow(10))
wordcloud(corpus, min.freq = 1, max.words = 60,
random.order = FALSE, rot.per = 0.35,
colors=brewer.pal(8,"Dark2"))
wordcloud(corpus, min.freq = 1, max.words = 60,
random.order = FALSE, rot.per = 0.35,
colors=brewer.pal(11,"Dark2"))
wordcloud(corpus, min.freq = 1, max.words = 60,
random.order = FALSE, rot.per = 0.35,
colors=brewer.pal(50,"Dark2"))
wordcloud(corpus, min.freq = 1, max.words = 100,
random.order = FALSE, rot.per = 0.35,
colors=brewer.pal(50,"Dark2"))
wordcloud(corpus, min.freq = 1, max.words = 70,
random.order = FALSE, rot.per = 0,
colors=brewer.pal(50,"Dark2"))
wordcloud(corpus, min.freq = 1, max.words = 70,
random.order = FALSE, rot.per = 0.25,
colors=brewer.pal(50,"Dark2"))
wordcloud(corpus, min.freq = 1, max.words = 70,
random.order = FALSE, rot.per = 0.25,
colors=brewer.pal(50,"Dark2"),width=12,height=8, units='in', res=300)
wordcloud(corpus, min.freq = 1, max.words = 70,
random.order = FALSE, rot.per = 0.25,
colors=brewer.pal(1,"Dark2"),width=12,height=8, units='in', res=300)
wordcloud(corpus, min.freq = 1, max.words = 70,
random.order = FALSE, rot.per = 0.25,
colors=brewer.pal(1,"Dark2"),width=12,height=8, units='in')
wordcloud(corpus, min.freq = 1, max.words = 70,
random.order = FALSE, rot.per = 0.25,
colors=brewer.pal(1,"Dark2"),width=1,height=8, units='in')
wordcloud(corpus, min.freq = 1, max.words = 70,
random.order = FALSE, rot.per = 0.25,
colors=brewer.pal(1,"Dark2"),width=1,height=1, units='in')
wordcloud(corpus, min.freq = 1, max.words = 70,
random.order = FALSE, rot.per = 0.25,
colors=brewer.pal(1,"Dark2"),width=1,height=1)
wordcloud(corpus, min.freq = 1, max.words = 70,
random.order = FALSE, rot.per = 0.25,
colors=brewer.pal(1,"Dark2"),width=12,height=10)
wordcloud(corpus, min.freq = 1, max.words = 70,
random.order = FALSE, rot.per = 0.25,
colors=brewer.pal(1,"Dark2"),res=300)
wordcloud(corpus, min.freq = 1, max.words = 70,
random.order = FALSE, rot.per = 0.25,
colors=brewer.pal(1,"Dark2"),par(mar = rep(0, 4)),res=300)
wordcloud(corpus, min.freq = 1, max.words = 70,
random.order = FALSE, rot.per = 0.25,
colors=brewer.pal(1,"Dark2"),res=300)
wordcloud = WordCloud(width=800, height=400).generate(corpus)
wordcloud <- WordCloud(width=800, height=400).generate(corpus)
wordcloud(corpus, min.freq = 1, max.words = 70,
random.order = FALSE, rot.per = 0.25,
colors=brewer.pal(1,"Dark2"),res=300,scale=c(4,.5))
wordcloud(corpus, min.freq = 1, max.words = 70,
random.order = FALSE, rot.per = 0.25,
colors=brewer.pal("Dark2"),res=300,scale=c(4,.5))
wordcloud(corpus, min.freq = 1, max.words = 70,
random.order = FALSE, rot.per = 0.25,
colors=brewer.pal(10,"Dark2"),res=300,scale=c(4,.5))
wordcloud(corpus, min.freq = 1, max.words = 70,
random.order = FALSE, rot.per = 0.25,
colors=brewer.pal(10,"Dark2"),res=300,scale=c(12,.5))
wordcloud(corpus, min.freq = 1, max.words = 70,
random.order = FALSE, rot.per = 0.25,
colors=brewer.pal(10,"Dark2"),res=300,scale=c(12,.3))
#plotar gráfico de barras
barplot(aux, las=2, col = rainbow(10))
barplot(aux, las=2, col = rainbow(10), names.arg = d[1:10])
#plotar gráfico de barras
barplot(aux, las=2, col = rainbow(10), names.arg = aux[1:10])
barplot(aux, las=2, col = rainbow(10), names.arg = 10)
barplot(aux, las=2, col = rainbow(10), names.arg = 10)
barplot(aux[1:10], las=2, col = rainbow(10))
barplot(aux[1:10], las=2, col ="lightblue", main ="Most frequent words",)
barplot(fre[1:10,], las = 2, names.arg = aux[1:10,],
col ="lightblue", main ="Most frequent words",
ylab = "Word frequencies")
barplot(fre[1:10,], las = 2, names.arg = aux[1:10],
col ="lightblue", main ="Most frequent words",
ylab = "Word frequencies")
head(aux)
barplot(aux[1:10], las=2, col ="lightblue", main ="Most frequent words",)
#plotar gráfico de barras
barplot(aux[1:10], las=2, col ="lightblue", main ="Palavras mais usadas",)
#plotar gráfico de barras
barplot(aux[1:5], las=2, col ="lightblue", main ="Palavras mais usadas",)
barplot(aux, las=2, col = rainbow(10))
motivos <- read.csv("motivos.csv", header = T, stringsAsFactors = FALSE)
motivos <- read_csv("motivos.csv")
#colapsando todos os comentários em um vetor de uma posição
motivos <- paste(motivos$`2019.1`, collapse = " ")
#processar o texto é com tm
#converter os dados em um formato chamado corpus que
#pode ser processado pelo tm
VS <- VectorSource(motivos)
corpus <- Corpus(VS)
#Verificar o corpus gerado
inspect(corpus)
#limpeza
#tudo minúsculo
corpus <- tm_map(corpus, content_transformer(tolower))
#removendo pontuação
corpus <- tm_map(corpus, removePunctuation)
#removendo espaços extras em branco
corpus <- tm_map(corpus, stripWhitespace)
#remover numeros
corpus <- tm_map(corpus, removeNumbers)
#remover stopwords
corpus <- tm_map(corpus, removeWords, stopwords('portuguese'))
#verificação
inspect(corpus)
#converter para o formato de matrix
tdm <- as.matrix(TermDocumentMatrix(corpus))
#Fornecer as frequencias ordenadas de cada palavra
fre <- sort(rowSums(tdm), decreasing = TRUE)
#escolhedo um subconjunto dos dados
aux<- subset(fre, fre>2)
#plotar gráfico de barras
barplot(aux, las=2, col = rainbow(10))
#processar o texto é com tm
#converter os dados em um formato chamado corpus que
#pode ser processado pelo tm
VS <- VectorSource(tweets)
corpus <- Corpus(VS)
#Verificar o corpus gerado
inspect(corpus)
#limpeza
#tudo minúsculo
corpus <- tm_map(corpus, content_transformer(tolower))
#removendo pontuação
corpus <- tm_map(corpus, removePunctuation)
#removendo espaços extras em branco
corpus <- tm_map(corpus, stripWhitespace)
#remover numeros
corpus <- tm_map(corpus, removeNumbers)
#remover stopwords
corpus <- tm_map(corpus, removeWords, stopwords('portuguese'))
#verificação
inspect(corpus)
#converter para o formato de matrix
tdm <- as.matrix(TermDocumentMatrix(corpus))
#Fornecer as frequencias ordenadas de cada palavra
fre <- sort(rowSums(tdm), decreasing = TRUE)
#escolhedo um subconjunto dos dados
aux<- subset(fre, fre>2)
#plotar gráfico de barras
barplot(aux[1:5], las=2, col ="lightblue", main ="Palavras mais usadas",)
head(aux)
barplot(aux[1:25], las=2, col ="lightblue", main ="Palavras mais usadas",)
#plotar gráfico de barras
barplot(aux[1:25], las=1, col ="lightblue", main ="Palavras mais usadas",)
typeof(aux)
head(aux)
head(aux)
typeof(fre)
head(fre)
aux2 <- aux[1:25]
#plotar gráfico de barras
barplot(aux2, las=2, col ="lightblue", main ="Palavras mais usadas",)
aux2 <- aux[1:25]
#plotar gráfico de barras
barplot(aux2, las=2, col ="lightblue", main ="Palavras mais usadas",)
head(aux2)
head(aux2$head())
head(aux2[1])
head(colnames(aux2))
colnames(aux2)
row.names(aux2)
row.names(aux2)
print(row.names(aux2))
head(aux2[[2]])
head(aux2[[1]])
head(aux2[1[1]])
head(aux2[1[]])
head(aux2[1[]])
head(aux2[1])
head(aux2[1][1])
head(aux2[1,[1]])
head(aux2[1[1]])
dimnames(aux2[1])
dimnames(aux2)
names(aux2)
barplot(aux2, las=2, col ="lightblue", main ="Palavras mais usadas",names.arg = names(aux2) )
aux2 <- aux[1:20]
#plotar gráfico de barras
barplot(aux2, las=2, col ="lightblue", main ="Palavras mais usadas",names.arg = names(aux2) )
#plotar gráfico de barras
barplot(aux2, las=1, col ="lightblue", main ="Palavras mais usadas",names.arg = names(aux2) )
barplot(aux2, las=5, col ="lightblue", main ="Palavras mais usadas",names.arg = names(aux2) )
barplot(aux2, las=2, col ="lightblue", main ="Palavras mais usadas",names.arg = names(aux2), density=10 )
#plotar gráfico de barras
barplot(aux2, las=2, col ="lightblue", main ="Palavras mais usadas",names.arg = names(aux2), density=1 )
tabela <-table(aux2)
head(tabela)
age <- c(17,18,18,17,18,19,18,16,18,18)
table(age)
table(corpus)
table(tdm)
head(table(tdm))
barplot(table(tdm),
main="Age Count of 10 Students",
xlab="Age",
ylab="Count",
border="red",
col="blue",
density=10
)
barplot(table(age),
main="Age Count of 10 Students",
xlab="Age",
ylab="Count",
border="red",
col="blue",
density=10
)
barplot(aux2, las=2, col ="lightblue", main ="Palavras mais usadas",names.arg = names(aux2))
barplot(aux2, las=2, col ="lightblue", main ="Palavras mais usadas",names.arg = names(aux2))
barplot(aux2, las=2, col ="lightblue", main ="Palavras mais usadas",names.arg = names(aux2), horiz=T,)
barplot(table(age),
main="Age Count of 10 Students",
xlab="Age",
ylab="Count",
border="red",
col="blue",
density=10,
horiz=T,
)
barplot(d[1:10,]$freq, las = 2, names.arg = d[1:10,]$word,
col ="lightblue", main ="Most frequent words",
ylab = "Word frequencies")
wordcloud(corpus, min.freq = 1, max.words = 70,
random.order = FALSE, rot.per = 0.25,
colors=brewer.pal(10,"Dark2"),res=300,scale=c(12,.3))
wordcloud(corpus, min.freq = 1, max.words = 70,
random.order = FALSE, rot.per = 0.25,
colors=brewer.pal(10,"Dark2"),res=150,scale=c(12,.3))
barplot(aux2, las=2, col ="lightblue", main ="Palavras mais usadas",names.arg = names(aux2), horiz=T,)
wordcloud(corpus, min.freq = 1, max.words = 70,
random.order = FALSE, rot.per = 0.25,
colors=brewer.pal(10,"Dark2"),res=10,scale=c(12,.3))
barplot(aux2, las=2, col ="lightblue", main ="Palavras mais usadas",names.arg = names(aux2), horiz=T,)
age <- c(17,18,18,17,18,19,18,16,18,18)
table(tdm)
head(table(tdm))
barplot(table(age),
main="Age Count of 10 Students",
xlab="Age",
ylab="Count",
border="red",
col="blue",
density=10,
horiz=T,
)
library(rtweet)
library(tm)
library(wordcloud)
library(syuzhet)
library(dplyr)
tweets <- search_tweets("@UP80BR", n=500, lang="pt")
typeof(tweets)
#convertendo para formato DF
#tweets <- twListToDF(tweets)
dataFrame <- tweets %>%
as_tibble()
tweets <- dataFrame$text
#pontuando os tweets
s<-get_nrc_sentiment(tweets)
#plotando grafico com sentimentos
barplot(colSums(s), las=2, col=rainbow(10),
ylab = "Contagem", main = "Sentimentos com a palavra @UP80BR em 500 tweets")
#processar o texto é com tm
#converter os dados em um formato chamado corpus que
#pode ser processado pelo tm
VS <- VectorSource(tweets)
corpus <- Corpus(VS)
#Verificar o corpus gerado
inspect(corpus)
#limpeza
#tudo minúsculo
corpus <- tm_map(corpus, content_transformer(tolower))
#removendo pontuação
corpus <- tm_map(corpus, removePunctuation)
#removendo espaços extras em branco
corpus <- tm_map(corpus, stripWhitespace)
#remover numeros
corpus <- tm_map(corpus, removeNumbers)
#remover stopwords
corpus <- tm_map(corpus, removeWords, stopwords('portuguese'))
#verificação
inspect(corpus)
#converter para o formato de matrix
tdm <- as.matrix(TermDocumentMatrix(corpus))
#Fornecer as frequencias ordenadas de cada palavra
fre <- sort(rowSums(tdm), decreasing = TRUE)
#escolhedo um subconjunto dos dados
aux<- subset(fre, fre>2)
aux2 <- aux[1:20]
#plotar gráfico de barras
barplot(aux2, las=2, col ="lightblue", main ="Palavras mais usadas",names.arg = names(aux2), horiz=T,)
barplot(aux2, las=2, col ="lightblue", main ="Palavras mais usadas",names.arg = names(aux2),)
par(mar=c(11,4,4,4))
barplot(aux2, las=2, col ="lightblue", main ="Palavras mais usadas",names.arg = names(aux2),)
aux2 <- aux[1:25]
#plotar gráfico de barras
par(mar=c(11,4,4,4))
barplot(aux2, las=2, col ="lightblue", main ="Palavras mais usadas",names.arg = names(aux2),)
barplot(aux2, las=2, col ="#6d271b", main ="Palavras mais usadas",names.arg = names(aux2),)
wordcloud(corpus, min.freq = 1, max.words = 70,
random.order = FALSE, rot.per = 0.25,
colors=brewer.pal(10,"Dark2"),res=10,scale=c(12,.3))
par(mar=c(1,4,4,4))
wordcloud(corpus, min.freq = 1, max.words = 70,
random.order = FALSE, rot.per = 0.25,
colors=brewer.pal(10,"Dark2"),res=10,scale=c(12,.3))
wordcloud(corpus, min.freq = 1, max.words = 70,
random.order = FALSE, rot.per = 0.25,
colors=brewer.pal(10,"Dark2"),res=10,scale=c(12,.35))
wordcloud(corpus, min.freq = 1, max.words = 70,
random.order = FALSE, rot.per = 0.25,
colors=brewer.pal(10,"Dark2"),res=10,scale=c(10,.25))
wordcloud(corpus, min.freq = 1, max.words = 70,
random.order = FALSE, rot.per = 0.25,
colors=brewer.pal(10,"Dark2"),res=8,scale=c(10,.25))
wordcloud(corpus, min.freq = 1, max.words = 65,
random.order = FALSE, rot.per = 0.25,
colors=brewer.pal(10,"Dark2"),res=8,scale=c(10,.25))
save(tweets,file="tweetsUP.Rda")
warnings()
save(tweets, file = "tweetsUP.txt")
load("~/tweetsUP.Rda")
dataUP`<- load("~/tweetsUP.Rda")`
dataUP`<- load("~/tweetsUP.Rda")
'
``
dataUP<- load("~/tweetsUP.Rda")
head(dataUP)
write(tweets, file = "tweetsUP.txt")
setwd("~/programando/erre/aprendendoerre/aula10")
write(tweets, file = "tweetsUP.txt")
tweets <- search_tweets("@nautiluslink", n=500, lang="pt")
typeof(tweets)
#convertendo para formato DF
#tweets <- twListToDF(tweets)
dataFrame <- tweets %>%
as_tibble()
tweets <- dataFrame$text
library(rtweet)
library(tm)
library(wordcloud)
library(syuzhet)
library(dplyr)
tweets <- search_tweets("@nautiluslink", n=500, lang="pt")
typeof(tweets)
#convertendo para formato DF
#tweets <- twListToDF(tweets)
dataFrame <- tweets %>%
as_tibble()
tweets <- dataFrame$text
pode ser processado pelo tm
VS <- VectorSource(tweets)
corpus <- Corpus(VS)
#Verificar o corpus gerado
inspect(corpus)
#limpeza
#tudo minúsculo
corpus <- tm_map(corpus, content_transformer(tolower))
#removendo pontuação
corpus <- tm_map(corpus, removePunctuation)
#removendo espaços extras em branco
corpus <- tm_map(corpus, stripWhitespace)
#remover numeros
corpus <- tm_map(corpus, removeNumbers)
#remover stopwords
corpus <- tm_map(corpus, removeWords, stopwords('portuguese'))
#verificação
inspect(corpus)
#converter para o formato de matrix
tdm <- as.matrix(TermDocumentMatrix(corpus))
#Fornecer as frequencias ordenadas de cada palavra
fre <- sort(rowSums(tdm), decreasing = TRUE)
#escolhedo um subconjunto dos dados
aux<- subset(fre, fre>2)
aux2 <- aux[1:25]
#plotar gráfico de barras
par(mar=c(1,4,4,4))
barplot(aux2, las=2, col ="#6d271b", main ="Palavras mais usadas",names.arg = names(aux2),)
par(mar=c(12,4,4,4))
barplot(aux2, las=2, col ="#6d271b", main ="Palavras mais usadas",names.arg = names(aux2),)
par(mar=c(10,4,4,4))
barplot(aux2, las=2, col ="#6d271b", main ="Palavras mais usadas",names.arg = names(aux2),)
par(mar=c(8,4,4,4))
barplot(aux2, las=2, col ="#6d271b", main ="Palavras mais usadas",names.arg = names(aux2),)
aux2 <- aux[2:26]
#plotar gráfico de barras
par(mar=c(8,4,4,4))
barplot(aux2, las=2, col ="#6d271b", main ="Palavras mais usadas",names.arg = names(aux2),)
corpus <- tm_map(corpus, removeWords, stopwords('english'))
#converter para o formato de matrix
tdm <- as.matrix(TermDocumentMatrix(corpus))
#Fornecer as frequencias ordenadas de cada palavra
fre <- sort(rowSums(tdm), decreasing = TRUE)
#escolhedo um subconjunto dos dados
aux<- subset(fre, fre>2)
aux2 <- aux[2:26]
#plotar gráfico de barras
par(mar=c(8,4,4,4))
barplot(aux2, las=2, col ="#6d271b", main ="Palavras mais usadas",names.arg = names(aux2),)
wordcloud(corpus, min.freq = 1, max.words = 65,
random.order = FALSE, rot.per = 0.25,
colors=brewer.pal(10,"Dark2"),res=8,scale=c(10,.25))
tweets <- search_tweets("@UP80BR", n=500, lang="pt")
typeof(tweets)
#convertendo para formato DF
#tweets <- twListToDF(tweets)
dataFrame <- tweets %>%
as_tibble()
tweets <- dataFrame$text
#write(tweets, file = "tweetsUP.txt")
#pontuando os tweets
s<-get_nrc_sentiment(tweets)
#plotando grafico com sentimentos
barplot(colSums(s), las=2, col=rainbow(10),
ylab = "Contagem", main = "Sentimentos com a palavra @UP80BR em 500 tweets")
